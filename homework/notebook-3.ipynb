{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    dataframe = pd.read_csv(\n",
    "        \"../files/input/sentences.csv.zip\",\n",
    "        index_col=False,\n",
    "        compression=\"zip\",\n",
    "    )\n",
    "\n",
    "    data = dataframe.phrase\n",
    "    target = dataframe.target\n",
    "\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_split(x, y):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=123456,\n",
    "    )\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(estimator):\n",
    "\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        lowercase=True,\n",
    "        analyzer=\"word\",\n",
    "        token_pattern=r\"\\b[a-zA-Z]\\w+\\b\",\n",
    "        stop_words=\"english\",\n",
    "    )\n",
    "\n",
    "    transformer = TfidfTransformer()\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"vectorizer\", vectorizer),\n",
    "            (\"transformer\", transformer),\n",
    "            (\"estimator\", estimator),\n",
    "        ],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(estimator, param_grid, cv=5):\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return grid_search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    with open(\"estimator.pickle\", \"wb\") as file:\n",
    "        pickle.dump(estimator, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator():\n",
    "\n",
    "    import os\n",
    "    import pickle\n",
    "\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        return None\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_logistic_regression():\n",
    "\n",
    "#     from sklearn.linear_model import LogisticRegression\n",
    "#     from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "#     data, target = load_data()\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = make_train_test_split(\n",
    "#         x=data,\n",
    "#         y=target,\n",
    "#     )\n",
    "\n",
    "#     pipeline = make_pipeline(\n",
    "#         estimator=LogisticRegression(max_iter=1000),\n",
    "#     )\n",
    "\n",
    "#     estimator = make_grid_search(\n",
    "#         estimator=pipeline,\n",
    "#         param_grid={\n",
    "#             \"transformer__norm\": [\"l1\", \"l2\", None],\n",
    "#             \"transformer__use_idf\": [True, False],\n",
    "#             \"transformer__smooth_idf\": [True, False],\n",
    "#         },\n",
    "#         cv=5,\n",
    "#     )\n",
    "\n",
    "#     estimator.fit(x_train, y_train)\n",
    "\n",
    "#     best_estimator = load_estimator()\n",
    "\n",
    "#     if best_estimator is not None:\n",
    "\n",
    "#         saved_balanced_accuracy = balanced_accuracy_score(\n",
    "#             y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "#         )\n",
    "\n",
    "#         current_balanced_accuracy = balanced_accuracy_score(\n",
    "#             y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "#         )\n",
    "\n",
    "#         if current_balanced_accuracy < saved_balanced_accuracy:\n",
    "#             estimator = best_estimator\n",
    "\n",
    "#     save_estimator(estimator)\n",
    "\n",
    "\n",
    "# train_logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     18\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n\u001b[1;32m---> 23\u001b[0m \u001b[43muse_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m, in \u001b[0;36muse_estimator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m data \u001b[38;5;241m=\u001b[39m dataframe\u001b[38;5;241m.\u001b[39mphrase\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 16\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m prediction \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32md:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _distributor_init  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32md:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     20\u001b[0m     _safe_tags,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n",
      "File \u001b[1;32md:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclass_weight\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _joblib\n",
      "File \u001b[1;32msklearn\\utils\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "def use_estimator():\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    dataframe = pd.read_csv(\n",
    "        \"../files/input/sentences.csv.zip\",\n",
    "        index_col=False,\n",
    "        compression=\"zip\",\n",
    "    )\n",
    "\n",
    "    data = dataframe.phrase\n",
    "\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    prediction = estimator.predict(data)\n",
    "\n",
    "    return prediction\n",
    "\n",
    "\n",
    "use_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.0.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\UNAL\\Tercer Semestre\\Analitica Predictiva\\2024-2-PRE-08-pipelines-Gorrego15\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute '_PredictScorer' on <module 'sklearn.metrics._scorer' from 'd:\\\\UNAL\\\\Tercer Semestre\\\\Analitica Predictiva\\\\2024-2-PRE-08-pipelines-Gorrego15\\\\.venv\\\\lib\\\\site-packages\\\\sklearn\\\\metrics\\\\_scorer.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Balanced Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbalanced_accuracy_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbalanced_accuracy_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m           Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m \u001b[43mcheck_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 16\u001b[0m, in \u001b[0;36mcheck_estimator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m x_train, x_test, y_train_true, y_test_true \u001b[38;5;241m=\u001b[39m make_train_test_split(\n\u001b[0;32m     11\u001b[0m     x\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m     12\u001b[0m     y\u001b[38;5;241m=\u001b[39mtarget,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m---> 16\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(x_train)\n\u001b[0;32m     19\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute '_PredictScorer' on <module 'sklearn.metrics._scorer' from 'd:\\\\UNAL\\\\Tercer Semestre\\\\Analitica Predictiva\\\\2024-2-PRE-08-pipelines-Gorrego15\\\\.venv\\\\lib\\\\site-packages\\\\sklearn\\\\metrics\\\\_scorer.py'>"
     ]
    }
   ],
   "source": [
    "def check_estimator():\n",
    "\n",
    "    import pickle\n",
    "\n",
    "    import pandas as pd\n",
    "    from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "    data, target = load_data()\n",
    "\n",
    "    x_train, x_test, y_train_true, y_test_true = make_train_test_split(\n",
    "        x=data,\n",
    "        y=target,\n",
    "    )\n",
    "\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    y_train_pred = estimator.predict(x_train)\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "\n",
    "    accuracy_train = round(accuracy_score(y_train_true, y_train_pred), 4)\n",
    "    accuracy_test = round(accuracy_score(y_test_true, y_test_pred), 4)\n",
    "    balanced_accuracy_train = round(\n",
    "        balanced_accuracy_score(y_train_true, y_train_pred), 4\n",
    "    )\n",
    "    balanced_accuracy_test = round(balanced_accuracy_score(y_test_true, y_test_pred), 4)\n",
    "\n",
    "    print(estimator.best_estimator_, \":\", sep=\"\")\n",
    "    print(f\"  Balanced Accuracy: {balanced_accuracy_test} ({balanced_accuracy_train})\")\n",
    "    print(f\"           Accuracy: {accuracy_test} ({accuracy_train})\")\n",
    "\n",
    "\n",
    "check_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_classifier():\n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    data, target = load_data()\n",
    "\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(\n",
    "        x=data,\n",
    "        y=target,\n",
    "    )\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        estimator=MLPClassifier(max_iter=10000),\n",
    "    )\n",
    "\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline,\n",
    "        param_grid={\n",
    "            \"transformer__norm\": [\"l1\", \"l2\", None],\n",
    "            \"transformer__use_idf\": [True, False],\n",
    "            \"transformer__smooth_idf\": [True, False],\n",
    "            \"estimator__hidden_layer_sizes\": [(1,), (5,), (5, 5)],\n",
    "            \"estimator__solver\": [\"adam\"],\n",
    "            \"estimator__learning_rate_init\": [0.01, 0.001, 0.0001],\n",
    "        },\n",
    "        cv=5,\n",
    "    )\n",
    "\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    best_estimator = load_estimator()\n",
    "\n",
    "    if best_estimator is not None:\n",
    "\n",
    "        saved_balanced_accuracy = balanced_accuracy_score(\n",
    "            y_true=y_test, y_pred=best_estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        current_balanced_accuracy = balanced_accuracy_score(\n",
    "            y_true=y_test, y_pred=estimator.predict(x_test)\n",
    "        )\n",
    "\n",
    "        if current_balanced_accuracy < saved_balanced_accuracy:\n",
    "            estimator = best_estimator\n",
    "\n",
    "    save_estimator(estimator)\n",
    "\n",
    "\n",
    "train_mlp_classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
